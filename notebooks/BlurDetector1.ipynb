{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting blurry images with a CNN\n",
    "This notebook contains code to classify images as sharp or blurry, based on an convolutional neural network (CNN) that was trained on a dataset that contains both sharp and blurry images, as preprocessed in the PreProcessing1.ipynb notebook (from the MR4 set).\n",
    "\n",
    "A CNN is implemented with Keras with a TensorFlow backend.\n",
    "\n",
    "The rationale behind using a CNN is that certain filters (kernels) can be used to detect blur. By training the CNN, the network will (most likely) generate filters work like this. An example of such a filter is a LaPlacian[1]\n",
    "\n",
    "The end of the notebook contains some examples of predicted and wrongly predicted images.\n",
    "\n",
    "[1] https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import math\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To make it reproducible :-)\n",
    "random.seed(21)\n",
    "tf.set_random_seed(20)\n",
    "\n",
    "# Tested on tensorflow version 1.5.0\n",
    "print(tf.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = 400            # input dimension of images in pixels (assumes a square image)\n",
    "NUM_OF_CATEGORIES = 1     # total number of categories\n",
    "\n",
    "INPUT_FOLDER = '../../processed_multiblur_400p/'\n",
    "ORIG_FOLDER = 'orig/'\n",
    "BLUR_FOLDER = 'blur/'\n",
    "TEST_SPLIT_FRAC = 0.2\n",
    "CHECKPOINT_FILEPATH = \"../../blurdetector400p-{epoch:02d}-{val_acc:.2f}.h5\"\n",
    "\n",
    "FIT_BATCH_SIZE = 64\n",
    "FIT_MAX_EPOCHS = 50\n",
    "FIT_VALIDATION_SPLIT = 0.2\n",
    "\n",
    "FIT_STOP_MIN_DELTA = 0.01\n",
    "FIT_STOP_PATIENCE = 2\n",
    "\n",
    "\n",
    "MODEL_STRUCTURE = [\n",
    "    keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(INPUT_DIM,INPUT_DIM,3)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'),\n",
    "#     keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same'),\n",
    "#     keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same'),\n",
    "#     keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(100),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(NUM_OF_CATEGORIES, activation='sigmoid'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test/train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_content = glob.glob(INPUT_FOLDER+ORIG_FOLDER+'*.jpg')\n",
    "input_filenames = [x.split('/')[-1] for x in dir_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 224 test items from total set 1123\n"
     ]
    }
   ],
   "source": [
    "# Every filenames appears twice: once in blur and once in orig\n",
    "# We split the set of filenames into a training and a test set\n",
    "# Please note: a filename appears twice: once in blur and once in orig\n",
    "\n",
    "num_test_items = math.floor( len(input_filenames) * TEST_SPLIT_FRAC )\n",
    "print('Selecting {} test items from total set {}'.format(num_test_items,len(input_filenames)))\n",
    "\n",
    "random.shuffle(input_filenames)\n",
    "\n",
    "test_items = input_filenames[:num_test_items]\n",
    "train_items = input_filenames[num_test_items:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading train & test images into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_images(items, orig_folder, blur_folder):\n",
    "    y = []\n",
    "    x = []\n",
    "\n",
    "    for file in items:\n",
    "        orig = cv.imread(orig_folder+file)\n",
    "        blur = cv.imread(blur_folder+file)\n",
    "\n",
    "        x.append(orig)\n",
    "        y.append(1) # original sample = positive = 1\n",
    "\n",
    "        x.append(blur)\n",
    "        y.append(0) # blurred sample = negative = 0\n",
    "\n",
    "    # Randomize the set (otherwise it will always be 10101010101010)\n",
    "    zipped = list(zip(x,y))\n",
    "    random.shuffle(zipped)\n",
    "    x,y = zip(*zipped)\n",
    "    \n",
    "    x_set = np.stack(x, axis=0)\n",
    "    \n",
    "    return x_set, np.asarray(y)\n",
    "\n",
    "\n",
    "orig_folder = INPUT_FOLDER+ORIG_FOLDER\n",
    "blur_folder = INPUT_FOLDER+BLUR_FOLDER\n",
    "x_test, y_test = load_images(test_items, orig_folder, blur_folder)\n",
    "x_train, y_train = load_images(train_items, orig_folder, blur_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 1798\n",
      "Size of test set: 448\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training set: {}\".format(len(y_train)))\n",
    "print(\"Size of test set: {}\".format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 400, 400, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               64000100  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 64,029,693\n",
      "Trainable params: 64,029,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(MODEL_STRUCTURE)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(lr=1e-6), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 360 samples\n",
      "Epoch 1/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9081 - acc: 0.4901 Epoch 00001: val_acc improved from -inf to 0.49167, saving model to ../../blurdetector400p-01-0.49.h5\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 290s 202ms/step - loss: 7.8983 - acc: 0.4910 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 2/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9146 - acc: 0.5036 Epoch 00002: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 285s 199ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 3/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9033 - acc: 0.5043 Epoch 00003: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 292s 203ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 4/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9712 - acc: 0.5000 Epoch 00004: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 280s 195ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 5/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9599 - acc: 0.5007 Epoch 00005: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 298s 207ms/step - loss: 7.9268 - acc: 0.5028 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 6/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9033 - acc: 0.5043 Epoch 00006: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 286s 199ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 7/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9485 - acc: 0.5014 Epoch 00007: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 283s 197ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 8/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 6s - loss: 7.9259 - acc: 0.5028 Epoch 00008: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 315s 219ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 9/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 6s - loss: 7.9825 - acc: 0.4993 Epoch 00009: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 324s 226ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 10/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 6s - loss: 7.9033 - acc: 0.5043 Epoch 00010: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 314s 218ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 11/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9372 - acc: 0.5021 Epoch 00011: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 284s 198ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 12/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9372 - acc: 0.5021 Epoch 00012: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 280s 194ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 13/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9372 - acc: 0.5021 Epoch 00013: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 303s 211ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 14/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 6s - loss: 7.9712 - acc: 0.5000 Epoch 00014: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 314s 218ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 15/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 6s - loss: 7.9372 - acc: 0.5021 Epoch 00015: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 313s 218ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 16/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 6s - loss: 7.9146 - acc: 0.5036 Epoch 00016: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 312s 217ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 17/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 7.9146 - acc: 0.5036 Epoch 00017: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 284s 197ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 18/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 5s - loss: 8.0052 - acc: 0.4979 Epoch 00018: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 311s 217ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 19/50\n",
      "1408/1438 [============================>.]1408/1438 [============================>.] - ETA: 6s - loss: 7.9146 - acc: 0.5036 Epoch 00019: val_acc did not improve\n",
      "1438/1438 [==============================]1438/1438 [==============================] - 314s 218ms/step - loss: 7.9379 - acc: 0.5021 - val_loss: 8.1040 - val_acc: 0.4917\n",
      "\n",
      "Epoch 20/50\n",
      "1152/1438 [=======================>......]1152/1438 [=======================>......] - ETA: 57s - loss: 7.9850 - acc: 0.4991 "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=FIT_BATCH_SIZE, \n",
    "          epochs=FIT_MAX_EPOCHS,\n",
    "          callbacks=[\n",
    "#               keras.callbacks.EarlyStopping(monitor='acc', min_delta=FIT_STOP_MIN_DELTA, patience=FIT_STOP_PATIENCE)\n",
    "              keras.callbacks.ModelCheckpoint(CHECKPOINT_FILEPATH, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "          ],\n",
    "          validation_split=FIT_VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the model prediction\n",
    "y_tested = model.predict(x_test)\n",
    "\n",
    "# Since the model has a sigmoid function in the last dense layer, outputs are between 0-1. Squash into binary...\n",
    "decision_boundary = 0.5\n",
    "y_tested[ y_tested > decision_boundary ] = 1\n",
    "y_tested[ y_tested <= decision_boundary ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "num_total = 0\n",
    "correctly_predicted = y_tested.reshape(-1) == y_test\n",
    "\n",
    "for state in correctly_predicted:\n",
    "    if state == True:\n",
    "        num_correct += 1\n",
    "    num_total += 1\n",
    "\n",
    "accuracy = num_correct/num_total\n",
    "print(\"Accuracy on test set: {}%\".format(round(accuracy,4)*100))\n",
    "print(\"Number of images wrongly predicted: {}\".format(len(correctly_predicted[correctly_predicted==False])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datestamp = datetime.datetime.now().strftime('%Y%m%d-%H%M')\n",
    "# model.save('blurdetector_partialblurrectangular_{}.h5'.format(datestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show random images with truth/prediction from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show = 5\n",
    "labels = {0:'blur', 1:'sharp'}\n",
    "\n",
    "for i in range(show):\n",
    "    \n",
    "    random_draw = random.randint(0,len(y_test))\n",
    "    \n",
    "    img = x_test[random_draw]\n",
    "    truth = int(y_test[random_draw])\n",
    "    predicted = int(y_tested[random_draw])\n",
    "    \n",
    "    plt.title('Truth: {t}, Predicted: {p}'.format(t=labels[truth], p=labels[predicted]))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show incorrectly predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the wrongly predicted ones\n",
    "wrongs = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] != y_tested[i]:\n",
    "        wrong = {\n",
    "            'image': x_test[i],\n",
    "            'truth': int(y_test[i]),\n",
    "            'pred': int(y_tested[i]),\n",
    "        }\n",
    "        wrongs.append(wrong)\n",
    "print('Found wrongs: {}'.format(len(wrongs)))\n",
    "\n",
    "# Plot the wrong predicted ones\n",
    "for wrong in wrongs[0:min(20,len(wrongs))]:\n",
    "    plt.title('Truth: {t}, Predicted: {p}'.format(t=labels[wrong['truth']], p=labels[wrong['pred']]))\n",
    "    plt.imshow(wrong['image'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
